![Introduction](https://github.com/wmeiqi/MMAW-UCAS2024/assets/35912099/ac3a4cc4-fb19-495f-8984-6b84bbe13877)

# MMAW-UCAS2024
In this work, we introduce a novel multimodal benchmark, MMAW-UCAS2024, accompanied by an automated strategy for hand keypoint annotation to label hand poses in each frame. To ensure the dataset's generalizability to outdoor settings, we have incorporated outdoor scene data. We anticipate that the inclusion of depth information will advance research in air-writing and stereo vision. The MMAW-UCAS2024 benchmark includes 221 participants, 103,188 videos, and 8,849,131 RGB video and depth frames with character and hand pose annotations.

# Demo

https://github.com/wmeiqi/MMAW-UCAS2024/assets/35912099/79623cd1-f4bd-489d-b31d-ba3e7f5594f8

# Dataset Examples


![Dataset Examples](https://github.com/wmeiqi/MMAW-UCAS2024/assets/35912099/cbd9fbfa-aecd-432f-97c1-0a8eb8900689)

# Download
[Baiduyun disk MMAW-UCAS2024](https://pan.baidu.com/s/1SOlA2T12RrYwd9l7TDZg-g?pwd=3tg8)

[GoogleDrive MMAW-UCAS2024](https://drive.google.com/drive/folders/1SBW6YMh1ySnJGhm6G3M4UDKzrLyGA1c5?usp=sharing)


# More Details
To be continued...
<!--This is the repository that contains source code for the [AWCV website](https://wmeiqi.github.io/AWCV).-->

<!--If you find AWCV-100K useful for your work please cite:
```
@article{awcv
  author    = {},
  title     = {},
  journal   = {},
  year      = {},
}
```-->

# Website License
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
